{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relabel uncertainty\n",
    "\n",
    "Relabeling of uncertainty for SelfTrained approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from typing import List, Union\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from google.cloud import storage\n",
    "\n",
    "import logging\n",
    "\n",
    "# CheXpert pathologies on original paper\n",
    "pathologies = ['Atelectasis',\n",
    "               'Cardiomegaly',\n",
    "               'Consolidation',\n",
    "               'Edema',\n",
    "               'Pleural Effusion']\n",
    "\n",
    "# Uncertainty policies on original paper\n",
    "uncertainty_policies = ['U-Ignore',\n",
    "                        'U-Zeros',\n",
    "                        'U-Ones',\n",
    "                        'U-SelfTrained',\n",
    "                        'U-MultiClass']\n",
    "\n",
    "\n",
    "# #####################\n",
    "# # Create a Dataset ##\n",
    "# #####################\n",
    "class UncetaintyOnlyCheXpertDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 data_path: Union[str, None] = None,\n",
    "                 uncertainty_policy: str = 'U-Ones',\n",
    "                 logger: logging.Logger = logging.getLogger(__name__),\n",
    "                 pathologies: List[str] = pathologies,\n",
    "                 train: bool = True,\n",
    "                 resize_shape: tuple = (256, 256)) -> None:\n",
    "        \"\"\" Innitialize dataset and preprocess according to uncertainty policy.\n",
    "\n",
    "        Args:\n",
    "            data_path (str): Path to csv file.\n",
    "            uncertainty_policy (str): Uncertainty policies compared in the\n",
    "            original paper.\n",
    "            Check if options are implemented. Options: 'U-Ignore', 'U-Zeros',\n",
    "            'U-Ones', 'U-SelfTrained', and 'U-MultiClass'.\n",
    "            logger (logging.Logger): Logger to log events during training.\n",
    "            pathologies (List[str], optional): Pathologies to classify.\n",
    "            Defaults to 'Atelectasis', 'Cardiomegaly', 'Consolidation',\n",
    "            'Edema', and 'Pleural Effusion'.\n",
    "            transform (type): method to transform image.\n",
    "            train (bool): If true, returns data selected for training, if not,\n",
    "            returns data selected for validation (dev set), as the CheXpert\n",
    "            research group splitted.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "\n",
    "        if not (uncertainty_policy in uncertainty_policies):\n",
    "            logger.error(\n",
    "                \"Unknown uncertainty policy. Known policies: \" +\n",
    "                f\"{uncertainty_policies}\")\n",
    "            return None\n",
    "\n",
    "        split = 'train' if train else 'valid'\n",
    "        csv_path = f\"CheXpert-v1.0/{split}.csv\"\n",
    "        path = str(data_path) + csv_path\n",
    "\n",
    "        self.in_cloud = False\n",
    "\n",
    "        data = pd.DataFrame()\n",
    "        try:\n",
    "            data = pd.read_csv(path)\n",
    "            data['Path'] = data_path + data['Path']\n",
    "            logger.info(\"Local database found.\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Couldn't read csv at path {path}./n{e}\")\n",
    "            try:\n",
    "                # Find files at gcp\n",
    "                project_id = 'labshurb'\n",
    "\n",
    "                storage_client = storage.Client(project=project_id)\n",
    "                self.bucket = storage_client.bucket(\n",
    "                    'chexpert_database_stanford')\n",
    "\n",
    "                blob = self.bucket.get_blob(csv_path)\n",
    "                blob.download_to_filename('tmp.csv')\n",
    "                data = pd.read_csv('tmp.csv')\n",
    "\n",
    "                self.in_cloud = True\n",
    "                logger.info(\"Cloud database found.\")\n",
    "\n",
    "            except Exception as e_:\n",
    "                logger.error(f\"Couldn't reach file at path {path}./n{e_}\")\n",
    "                quit()\n",
    "\n",
    "        data.set_index('Path', inplace=True)\n",
    "\n",
    "        # data = data.loc[data['Frontal/Lateral'] == 'Frontal'].copy()\n",
    "        data = data.loc[:, pathologies].copy()\n",
    "\n",
    "        # it will change for 15 in case of multiclass\n",
    "        label_cols = 5\n",
    "\n",
    "        data.fillna(0, inplace=True)\n",
    "\n",
    "        # U-Ignore\n",
    "        if uncertainty_policy == uncertainty_policies[0]:\n",
    "            # the only change is in the loss function, we mask the -1 labels\n",
    "            # in the calculation\n",
    "            pass\n",
    "\n",
    "        # U-Zeros\n",
    "        elif uncertainty_policy == uncertainty_policies[1]:\n",
    "            data.replace({-1: 0}, inplace=True)\n",
    "\n",
    "        # U-Ones\n",
    "        elif uncertainty_policy == uncertainty_policies[2]:\n",
    "            data.replace({-1: 1}, inplace=True)\n",
    "\n",
    "        # U-SelfTrained\n",
    "        elif uncertainty_policy == uncertainty_policies[3]:\n",
    "            logger.warning(\n",
    "                f\"Using {uncertainty_policy} uncertainty policy, \" +\n",
    "                \"make sure there are no uncertainty labels in the dataset.\")\n",
    "            return None\n",
    "\n",
    "        # U-MultiClass\n",
    "        elif uncertainty_policy == uncertainty_policies[4]:\n",
    "            #data.replace({-1: 2}, inplace=True)\n",
    "\n",
    "            one_hot_0 = [1., 0., 0.]\n",
    "            one_hot_1 = [0., 1., 0.]\n",
    "            one_hot_2 = [0., 0., 1.]\n",
    "\n",
    "            data.loc[:, pathologies] = data.map(lambda x: one_hot_0 if x == 0 else one_hot_1 if x == 1 else one_hot_2).to_numpy()\n",
    "\n",
    "            label_cols = 15\n",
    "\n",
    "        data = data[(data == -1).any(axis=1)].copy()\n",
    "\n",
    "        self.image_names = data.index.to_numpy()\n",
    "        self.labels = np.array(\n",
    "            data.loc[:, pathologies].values.tolist()\n",
    "            ).reshape((-1, label_cols))\n",
    "        self.transform = T.Compose([\n",
    "                  T.Resize(resize_shape),\n",
    "                  T.ToTensor(),\n",
    "                  T.Normalize(mean=[0.5330], std=[0.0349])\n",
    "              ])  # whiten with dataset mean and stdif transform)\n",
    "\n",
    "\n",
    "    def __getitem__(self, index: int) -> Union[np.array, Tensor]:\n",
    "        \"\"\" Returns image and label from given index.\n",
    "\n",
    "        Args:\n",
    "            index (int): Index of sample in dataset.\n",
    "\n",
    "        Returns:\n",
    "            np.array: Array of grayscale image.\n",
    "            torch.Tensor: Tensor of labels.\n",
    "        \"\"\"\n",
    "        if self.in_cloud:\n",
    "            img_bytes = self.bucket.blob(\n",
    "                self.image_names[index]).download_as_bytes()\n",
    "            # .download_to_filename('tmp.jpg')\n",
    "            img = Image.open(io.BytesIO(img_bytes)).convert('RGB')\n",
    "\n",
    "        else:\n",
    "            img = Image.open(self.image_names[index]).convert('RGB')\n",
    "        img = self.transform(img)\n",
    "\n",
    "        label = self.labels[index].astype(np.float32)\n",
    "        return {\"pixel_values\": img, \"labels\": label}\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\" Return length of dataset.\n",
    "\n",
    "        Returns:\n",
    "            int: length of dataset.\n",
    "        \"\"\"\n",
    "        return len(self.image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import sys\n",
    "from transformers import (\n",
    "    ViTForImageClassification,\n",
    "    AutoConfig\n",
    ")\n",
    "\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append('..')\n",
    "from src.chexpert import CheXpertDataset\n",
    "\n",
    "pathologies = ['Atelectasis',\n",
    "                'Cardiomegaly',\n",
    "                'Consolidation',\n",
    "                'Edema',\n",
    "                'Pleural Effusion']\n",
    "\n",
    "\n",
    "def get_predictions(ckpts, approach, data_path, train=True):\n",
    "    dataset = UncetaintyOnlyCheXpertDataset(\n",
    "                data_path=data_path,\n",
    "                uncertainty_policy=approach,\n",
    "                train=train,\n",
    "                resize_shape=(224, 224))\n",
    "    dataloader = DataLoader(dataset, batch_size=234, shuffle=False)\n",
    "\n",
    "    models = []\n",
    "    for checkpoint in ckpts:\n",
    "        model = ViTForImageClassification.from_pretrained(\n",
    "            f\"../output/25092023/google/vit-base-patch16-224/{approach}/checkpoint-{checkpoint}\",\n",
    "        ).eval()\n",
    "        models.append(model)\n",
    "\n",
    "    columns = pathologies\n",
    "    if approach == 'U-MultiClass':\n",
    "        columns = [comb[1]+comb[0] for comb in itertools.product(pathologies, ['neg_', 'pos_', 'unc_'])]\n",
    "\n",
    "    general_output = []\n",
    "    labels = pd.DataFrame(columns=pd.MultiIndex.from_product([['labels'], columns]))\n",
    "\n",
    "    for i_model, model in enumerate(models):\n",
    "        multiindex = pd.MultiIndex.from_product([[f'model_{i_model}'], columns], names=['model', 'pathology'])\n",
    "        model_output = pd.DataFrame(columns=multiindex)\n",
    "        for i_batch, sample_batched in enumerate(dataloader):\n",
    "            with torch.no_grad():\n",
    "                labels = pd.concat(\n",
    "                    [\n",
    "                        labels,\n",
    "                        pd.DataFrame(sample_batched['labels'], columns=pd.MultiIndex.from_product([['labels'], columns])),\n",
    "                    ],\n",
    "                    axis=0,\n",
    "                    ignore_index=True)\n",
    "                \n",
    "                model_output = pd.concat(\n",
    "                    [\n",
    "                        model_output,\n",
    "                        pd.DataFrame(model(sample_batched['pixel_values']).logits.numpy(), columns=multiindex),\n",
    "                    ],\n",
    "                    axis=0,\n",
    "                    ignore_index=True)\n",
    "                    \n",
    "        if len(general_output) == 0:\n",
    "            general_output = pd.merge(labels, model_output, left_index=True, right_index=True).copy()\n",
    "        else:\n",
    "            general_output = pd.merge(general_output, model_output, left_index=True, right_index=True)\n",
    "    return general_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hurbl\\AppData\\Local\\Temp\\ipykernel_23688\\748785343.py:51: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  labels = pd.concat(\n",
      "C:\\Users\\hurbl\\AppData\\Local\\Temp\\ipykernel_23688\\748785343.py:59: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  model_output = pd.concat(\n",
      "C:\\Users\\hurbl\\AppData\\Local\\Temp\\ipykernel_23688\\748785343.py:59: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  model_output = pd.concat(\n",
      "C:\\Users\\hurbl\\AppData\\Local\\Temp\\ipykernel_23688\\748785343.py:59: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  model_output = pd.concat(\n",
      "C:\\Users\\hurbl\\AppData\\Local\\Temp\\ipykernel_23688\\748785343.py:59: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  model_output = pd.concat(\n",
      "C:\\Users\\hurbl\\AppData\\Local\\Temp\\ipykernel_23688\\748785343.py:59: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  model_output = pd.concat(\n",
      "C:\\Users\\hurbl\\AppData\\Local\\Temp\\ipykernel_23688\\748785343.py:59: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  model_output = pd.concat(\n",
      "C:\\Users\\hurbl\\AppData\\Local\\Temp\\ipykernel_23688\\748785343.py:59: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  model_output = pd.concat(\n",
      "C:\\Users\\hurbl\\AppData\\Local\\Temp\\ipykernel_23688\\748785343.py:59: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  model_output = pd.concat(\n",
      "C:\\Users\\hurbl\\AppData\\Local\\Temp\\ipykernel_23688\\748785343.py:59: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  model_output = pd.concat(\n",
      "C:\\Users\\hurbl\\AppData\\Local\\Temp\\ipykernel_23688\\748785343.py:59: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  model_output = pd.concat(\n",
      "c:\\Users\\hurbl\\OneDrive\\Área de Trabalho\\Loon Factory\\repository\\Chest-X-Ray-Pathology-Classifier\\.env\\Lib\\site-packages\\pyarrow\\pandas_compat.py:373: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if _pandas_api.is_sparse(col):\n"
     ]
    }
   ],
   "source": [
    "approach = 'U-Ignore'\n",
    "id_ckpts = [4, 6, 7, 8, 9, 10, 11, 13, 14, 15]\n",
    "data_path = r\"C:/Users/hurbl/OneDrive/Área de Trabalho/Loon Factory/repository/Chest-X-Ray-Pathology-Classifier/data/raw/\"\n",
    "\n",
    "ckpts = [\n",
    "    '1090', # 4\n",
    "    '1526', # 6\n",
    "    '1744', # 7\n",
    "    '1962', # 8\n",
    "    '2180', # 9\n",
    "    '2398', # 10\n",
    "    '2616', # 11\n",
    "    '3052', # 13\n",
    "    '3270', # 14\n",
    "    '3488', # 15\n",
    "    ]\n",
    "\n",
    "ignore_results = get_predictions(\n",
    "    ckpts,\n",
    "    approach,\n",
    "    data_path=data_path,\n",
    "    train=True)\n",
    "\n",
    "ignore_results.to_parquet(f'results/valid_{approach}_for_selftrained.pqt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">labels</th>\n",
       "      <th colspan=\"5\" halign=\"left\">model_0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Pleural Effusion</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Pleural Effusion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.192969</td>\n",
       "      <td>-2.480345</td>\n",
       "      <td>-3.160272</td>\n",
       "      <td>-1.461431</td>\n",
       "      <td>-1.767798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.081272</td>\n",
       "      <td>-2.093229</td>\n",
       "      <td>-2.622588</td>\n",
       "      <td>-1.696654</td>\n",
       "      <td>-0.650424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.365313</td>\n",
       "      <td>-3.297892</td>\n",
       "      <td>-2.282577</td>\n",
       "      <td>-2.757240</td>\n",
       "      <td>-0.223821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.801268</td>\n",
       "      <td>-2.108772</td>\n",
       "      <td>-1.996155</td>\n",
       "      <td>-1.621541</td>\n",
       "      <td>1.135071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.406059</td>\n",
       "      <td>-2.037456</td>\n",
       "      <td>-3.590422</td>\n",
       "      <td>-1.265158</td>\n",
       "      <td>-2.009350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.072884</td>\n",
       "      <td>-2.707569</td>\n",
       "      <td>-2.094149</td>\n",
       "      <td>-0.956540</td>\n",
       "      <td>1.580486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.029691</td>\n",
       "      <td>-4.634951</td>\n",
       "      <td>-3.867409</td>\n",
       "      <td>-3.405506</td>\n",
       "      <td>-2.425060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.613808</td>\n",
       "      <td>-5.143997</td>\n",
       "      <td>-3.915619</td>\n",
       "      <td>-4.781992</td>\n",
       "      <td>-2.297644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.575031</td>\n",
       "      <td>-3.695695</td>\n",
       "      <td>-3.644741</td>\n",
       "      <td>-4.716095</td>\n",
       "      <td>-3.285170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.424528</td>\n",
       "      <td>-5.283208</td>\n",
       "      <td>-3.350040</td>\n",
       "      <td>-4.523763</td>\n",
       "      <td>-1.445287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>702 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         labels                                                       model_0  \\\n",
       "    Atelectasis Cardiomegaly Consolidation Edema Pleural Effusion Atelectasis   \n",
       "0           0.0          0.0           0.0   0.0              0.0   -1.192969   \n",
       "1          -1.0         -1.0          -1.0  -1.0             -1.0   -1.081272   \n",
       "2           0.0          0.0          -1.0   0.0              0.0   -1.365313   \n",
       "3           0.0          0.0          -1.0   0.0              0.0   -0.801268   \n",
       "4           0.0          0.0           0.0   1.0              0.0   -1.406059   \n",
       "..          ...          ...           ...   ...              ...         ...   \n",
       "697         0.0          0.0           0.0   0.0              1.0   -1.072884   \n",
       "698         0.0          0.0           0.0   0.0              0.0   -2.029691   \n",
       "699         0.0          0.0           0.0   0.0              0.0   -2.613808   \n",
       "700         0.0          0.0           0.0   0.0              0.0   -2.575031   \n",
       "701         0.0          0.0           0.0   0.0              0.0   -1.424528   \n",
       "\n",
       "                                                           \n",
       "    Cardiomegaly Consolidation     Edema Pleural Effusion  \n",
       "0      -2.480345     -3.160272 -1.461431        -1.767798  \n",
       "1      -2.093229     -2.622588 -1.696654        -0.650424  \n",
       "2      -3.297892     -2.282577 -2.757240        -0.223821  \n",
       "3      -2.108772     -1.996155 -1.621541         1.135071  \n",
       "4      -2.037456     -3.590422 -1.265158        -2.009350  \n",
       "..           ...           ...       ...              ...  \n",
       "697    -2.707569     -2.094149 -0.956540         1.580486  \n",
       "698    -4.634951     -3.867409 -3.405506        -2.425060  \n",
       "699    -5.143997     -3.915619 -4.781992        -2.297644  \n",
       "700    -3.695695     -3.644741 -4.716095        -3.285170  \n",
       "701    -5.283208     -3.350040 -4.523763        -1.445287  \n",
       "\n",
       "[702 rows x 10 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ignore_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
