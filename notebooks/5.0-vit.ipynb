{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from typing import List, Union\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from google.cloud import storage\n",
    "\n",
    "import logging\n",
    "\n",
    "# CheXpert pathologies on original paper\n",
    "pathologies = ['Atelectasis',\n",
    "               'Cardiomegaly',\n",
    "               'Consolidation',\n",
    "               'Edema',\n",
    "               'Pleural Effusion']\n",
    "\n",
    "# Uncertainty policies on original paper\n",
    "uncertainty_policies = ['U-Ignore',\n",
    "                        'U-Zeros',\n",
    "                        'U-Ones',\n",
    "                        'U-SelfTrained',\n",
    "                        'U-MultiClass']\n",
    "\n",
    "\n",
    "# #####################\n",
    "# # Create a Dataset ##\n",
    "# #####################\n",
    "class CheXpertDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 data_path: Union[str, None] = None,\n",
    "                 uncertainty_policy: str = 'U-Ones',\n",
    "                 logger: logging.Logger = logging.getLogger(__name__),\n",
    "                 pathologies: List[str] = pathologies,\n",
    "                 train: bool = True,\n",
    "                 resize_shape: tuple = (256, 256)) -> None:\n",
    "        \"\"\" Innitialize dataset and preprocess according to uncertainty policy.\n",
    "\n",
    "        Args:\n",
    "            data_path (str): Path to csv file.\n",
    "            uncertainty_policy (str): Uncertainty policies compared in the\n",
    "            original paper.\n",
    "            Check if options are implemented. Options: 'U-Ignore', 'U-Zeros',\n",
    "            'U-Ones', 'U-SelfTrained', and 'U-MultiClass'.\n",
    "            logger (logging.Logger): Logger to log events during training.\n",
    "            pathologies (List[str], optional): Pathologies to classify.\n",
    "            Defaults to 'Atelectasis', 'Cardiomegaly', 'Consolidation',\n",
    "            'Edema', and 'Pleural Effusion'.\n",
    "            transform (type): method to transform image.\n",
    "            train (bool): If true, returns data selected for training, if not,\n",
    "            returns data selected for validation (dev set), as the CheXpert\n",
    "            research group splitted.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "\n",
    "        if not (uncertainty_policy in uncertainty_policies):\n",
    "            logger.error(\n",
    "                \"Unknown uncertainty policy. Known policies: \" +\n",
    "                f\"{uncertainty_policies}\")\n",
    "            return None\n",
    "\n",
    "        split = 'train' if train else 'valid'\n",
    "        csv_path = f\"CheXpert-v1.0/{split}.csv\"\n",
    "        path = str(data_path) + csv_path\n",
    "\n",
    "        self.in_cloud = False\n",
    "\n",
    "        data = pd.DataFrame()\n",
    "        try:\n",
    "            data = pd.read_csv(path)\n",
    "            data['Path'] = data_path + data['Path']\n",
    "            logger.info(\"Local database found.\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Couldn't read csv at path {path}./n{e}\")\n",
    "            try:\n",
    "                # Find files at gcp\n",
    "                project_id = 'labshurb'\n",
    "\n",
    "                storage_client = storage.Client(project=project_id)\n",
    "                self.bucket = storage_client.bucket(\n",
    "                    'chexpert_database_stanford')\n",
    "\n",
    "                blob = self.bucket.get_blob(csv_path)\n",
    "                blob.download_to_filename('tmp.csv')\n",
    "                data = pd.read_csv('tmp.csv')\n",
    "\n",
    "                self.in_cloud = True\n",
    "                logger.info(\"Cloud database found.\")\n",
    "\n",
    "            except Exception as e_:\n",
    "                logger.error(f\"Couldn't reach file at path {path}./n{e_}\")\n",
    "                quit()\n",
    "\n",
    "        data.set_index('Path', inplace=True)\n",
    "\n",
    "        # data = data.loc[data['Frontal/Lateral'] == 'Frontal'].copy()\n",
    "        data = data.loc[:, pathologies].copy()\n",
    "\n",
    "        data.fillna(0, inplace=True)\n",
    "\n",
    "        # U-Ignore\n",
    "        if uncertainty_policy == uncertainty_policies[0]:\n",
    "            # the only change is in the loss function, we mask the -1 labels\n",
    "            # in the calculation\n",
    "            pass\n",
    "\n",
    "        # U-Zeros\n",
    "        elif uncertainty_policy == uncertainty_policies[1]:\n",
    "            data.replace({-1: 0}, inplace=True)\n",
    "\n",
    "        # U-Ones\n",
    "        elif uncertainty_policy == uncertainty_policies[2]:\n",
    "            data.replace({-1: 1}, inplace=True)\n",
    "\n",
    "        # U-SelfTrained\n",
    "        elif uncertainty_policy == uncertainty_policies[3]:\n",
    "            logger.warning(\n",
    "                f\"Using {uncertainty_policy} uncertainty policy, \" +\n",
    "                \"make sure there are no uncertainty labels in the dataset.\")\n",
    "            return None\n",
    "\n",
    "        # U-MultiClass\n",
    "        elif uncertainty_policy == uncertainty_policies[4]:\n",
    "            #data.replace({-1: 2}, inplace=True)\n",
    "\n",
    "            one_hot_0 = [1., 0., 0.]\n",
    "            one_hot_1 = [0., 1., 0.]\n",
    "            one_hot_2 = [0., 0., 1.]\n",
    "\n",
    "            data.loc[:, pathologies] = data.map(lambda x: one_hot_0 if x == 0 else one_hot_1 if x == 1 else one_hot_2).to_numpy()\n",
    "\n",
    "        #data = data.head(10).copy()\n",
    "\n",
    "        self.image_names = data.index.to_numpy()\n",
    "        self.labels = np.array(\n",
    "            data.loc[:, pathologies].values.tolist()\n",
    "            ).reshape((-1, 15))\n",
    "        self.transform = T.Compose([\n",
    "                  T.Resize(resize_shape),\n",
    "                  T.ToTensor(),\n",
    "                  T.Normalize(mean=[0.5330], std=[0.0349])\n",
    "              ])  # whiten with dataset mean and stdif transform)\n",
    "\n",
    "\n",
    "    def __getitem__(self, index: int) -> Union[np.array, Tensor]:\n",
    "        \"\"\" Returns image and label from given index.\n",
    "\n",
    "        Args:\n",
    "            index (int): Index of sample in dataset.\n",
    "\n",
    "        Returns:\n",
    "            np.array: Array of grayscale image.\n",
    "            torch.Tensor: Tensor of labels.\n",
    "        \"\"\"\n",
    "        if self.in_cloud:\n",
    "            img_bytes = self.bucket.blob(\n",
    "                self.image_names[index]).download_as_bytes()\n",
    "            # .download_to_filename('tmp.jpg')\n",
    "            img = Image.open(io.BytesIO(img_bytes)).convert('RGB')\n",
    "\n",
    "        else:\n",
    "            img = Image.open(self.image_names[index]).convert('RGB')\n",
    "        img = self.transform(img)\n",
    "\n",
    "        label = self.labels[index].astype(np.float32)\n",
    "        return {\"pixel_values\": img, \"labels\": label}\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\" Return length of dataset.\n",
    "\n",
    "        Returns:\n",
    "            int: length of dataset.\n",
    "        \"\"\"\n",
    "        return len(self.image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "from torch import nn\n",
    "from torch import masked_select\n",
    "\n",
    "\n",
    "class MaskedLossTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        # forward pass\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "\n",
    "        # compute custom loss (masking uncertanty in ignore approach)\n",
    "        mask = labels > -1.\n",
    "        criterion = nn.BCEWithLogitsLoss(device=model.device)\n",
    "        loss = criterion(\n",
    "            masked_select(logits.view(-1, self.model.config.num_labels), mask),\n",
    "            masked_select(labels.view(-1, self.model.config.num_labels), mask))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "\n",
    "class MultiOutputTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        # forward pass\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "\n",
    "        loss_fct = nn.CrossEntropyLoss().to(model.device)\n",
    "\n",
    "        loss_1 = loss_fct(logits[:, 0:3], labels[:, 0:3])\n",
    "        loss_2 = loss_fct(logits[:, 3:6], labels[:, 3:6])\n",
    "        loss_3 = loss_fct(logits[:, 6:9], labels[:, 6:9])\n",
    "        loss_4 = loss_fct(logits[:, 9:12], labels[:, 9:12])\n",
    "        loss_5 = loss_fct(logits[:, 12:], labels[:, 12:])\n",
    "\n",
    "        loss = (\n",
    "            loss_1 + loss_2 + loss_3 + loss_4 + loss_5\n",
    "        )/5.0\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hurbl\\OneDrive\\Área de Trabalho\\Loon Factory\\repository\\Chest-X-Ray-Pathology-Classifier\\.env\\Lib\\site-packages\\wandb\\sdk\\wandb_run.py:2088: UserWarning: Run (6kddvs8z) is finished. The call to `_console_raw_callback` will be ignored. Please make sure that you are using an active run.\n",
      "  def wrap_fallback() -> None:\n",
      " 20%|██        | 1/5 [19:03<1:16:13, 1143.46s/it]\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "from torchmetrics.classification import (\n",
    "    MultilabelAUROC,\n",
    "    MultilabelF1Score,\n",
    "    MultilabelAccuracy,\n",
    "    MulticlassAUROC,\n",
    "    MulticlassF1Score,\n",
    "    MulticlassAccuracy\n",
    ")\n",
    "\n",
    "#from chexpert import CheXpertDataset\n",
    "#from custom_trainer import MaskedLossTrainer, MultiOutputTrainer\n",
    "\n",
    "from transformers import (\n",
    "    ViTForImageClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "\n",
    "import wandb\n",
    "\n",
    "import logging\n",
    "log_fmt = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    "logging.basicConfig(level=logging.INFO, format=log_fmt)\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "# Uncertainty policies on original paper\n",
    "uncertainty_policies = ['U-Ignore',\n",
    "                        'U-Zeros',\n",
    "                        'U-Ones',\n",
    "                        'U-SelfTrained',\n",
    "                        'U-MultiClass']\n",
    "\n",
    "\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    device = 'cuda'\n",
    "\n",
    "\n",
    "def get_args():\n",
    "    '''Parses args.'''\n",
    "\n",
    "    parser = argparse.ArgumentParser(\"train_vit.py\")\n",
    "    parser.add_argument(\n",
    "        \"--epochs\",\n",
    "        \"-e\",\n",
    "        required=False,\n",
    "        type=int,\n",
    "        default=5,\n",
    "        help=\"Epochs of training\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--learning_rate\",\n",
    "        \"-l\",\n",
    "        required=False,\n",
    "        type=float,\n",
    "        default=4e-4,\n",
    "        help=\"learning rate of training\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--gradient_accumulation\",\n",
    "        \"-g\",\n",
    "        required=False,\n",
    "        type=int,\n",
    "        default=64,\n",
    "        help=\"Gradient accumulation steps\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--batch_size\",\n",
    "        \"-b\",\n",
    "        required=False,\n",
    "        type=int,\n",
    "        default=4,\n",
    "        help=\"Batch size\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--job_dir',\n",
    "        '-j',\n",
    "        required=False,\n",
    "        type=str,\n",
    "        default='.',\n",
    "        help='Bucket to store saved model, include gs://')\n",
    "    parser.add_argument(\n",
    "        '--data_path',\n",
    "        '-d',\n",
    "        required=False,\n",
    "        type=str,\n",
    "        default=r\"C:/Users/hurbl/OneDrive/Área de Trabalho/Loon Factory/repository/Chest-X-Ray-Pathology-Classifier/data/raw/\",\n",
    "        # default=\"gcs://chexpert_database_stanford/\",\n",
    "        help='Local or storage path to csv metadata file' \n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--uncertainty_policy',\n",
    "        '-u',\n",
    "        required=False,\n",
    "        type=str,\n",
    "        default=uncertainty_policies[-1],\n",
    "        help='Uncertainty policy'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--resize',\n",
    "        '-r',\n",
    "        required=False,\n",
    "        type=tuple,\n",
    "        default=(224, 224),\n",
    "        help='Resize dimensions'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--checkpoint',\n",
    "        '-c',\n",
    "        required=False,\n",
    "        type=str,\n",
    "        default='google/vit-base-patch16-224',\n",
    "        help='checkpoint to load from hugging face hub'\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "\n",
    "AUC = MultilabelAUROC(num_labels=5, average='macro', thresholds=None).to(device)\n",
    "F1 = MultilabelF1Score(num_labels=5, average='macro').to(device)\n",
    "ACC = MultilabelAccuracy(num_labels=5, average='macro').to(device)\n",
    "\n",
    "multiclassAUC = MulticlassAUROC(num_classes=3, average='macro', thresholds=None).to(device)\n",
    "multiclassF1 = MulticlassF1Score(num_classes=3, average='macro').to(device)\n",
    "multiclassACC = MulticlassAccuracy(num_classes=3, average='macro').to(device)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    logits = torch.from_numpy(logits).to(device)\n",
    "    labels = torch.from_numpy(labels).to(device).long()\n",
    "\n",
    "    if labels.shape[1] == 15:\n",
    "        label_1 = torch.argmax(labels[:, 0:3], dim=1).int()\n",
    "        label_2 = torch.argmax(labels[:, 3:6], dim=1).int()\n",
    "        label_3 = torch.argmax(labels[:, 6:9], dim=1).int()\n",
    "        label_4 = torch.argmax(labels[:, 9:12], dim=1).int()\n",
    "        label_5 = torch.argmax(labels[:, 12:], dim=1).int()\n",
    "\n",
    "\n",
    "        auc = (\n",
    "            multiclassAUC(logits[:, 0:3], label_1) +\n",
    "            multiclassAUC(logits[:, 3:6], label_2) +\n",
    "            multiclassAUC(logits[:, 6:9], label_3) +\n",
    "            multiclassAUC(logits[:, 9:12], label_4) +\n",
    "            multiclassAUC(logits[:, 12:], label_5)\n",
    "        )/5.\n",
    "\n",
    "        f1 = (\n",
    "            multiclassF1(logits[:, 0:3], label_1) +\n",
    "            multiclassF1(logits[:, 3:6], label_2) +\n",
    "            multiclassF1(logits[:, 6:9], label_3) +\n",
    "            multiclassF1(logits[:, 9:12], label_4) +\n",
    "            multiclassF1(logits[:, 12:], label_5)\n",
    "        )/5.\n",
    "\n",
    "        acc = (\n",
    "            multiclassACC(logits[:, 0:3], label_1) +\n",
    "            multiclassACC(logits[:, 3:6], label_2) +\n",
    "            multiclassACC(logits[:, 6:9], label_3) +\n",
    "            multiclassACC(logits[:, 9:12], label_4) +\n",
    "            multiclassACC(logits[:, 12:], label_5)\n",
    "        )/5.\n",
    "\n",
    "    else:\n",
    "        auc = AUC(logits, labels)\n",
    "        f1 = F1(logits, labels)\n",
    "        acc = ACC(logits, labels)\n",
    "\n",
    "    return {\n",
    "        'auc_roc_mean': auc.cpu().mean(),\n",
    "        'f1_mean': f1.cpu().mean(),\n",
    "        'acc_mean': acc.cpu()\n",
    "    }\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    with wandb.init(project=\"chexpert-vit\", job_type=\"train\", config=args,\n",
    "                    name=str(args.uncertainty_policy)+str(datetime.now().strftime(\"%d%m%Y_%H%M%S\")),\n",
    "                    tags=[\n",
    "                        args.uncertainty_policy,\n",
    "                        args.checkpoint]) as run:\n",
    "        config = run.config\n",
    "\n",
    "        train_dataset = CheXpertDataset(\n",
    "            data_path=config['data_path'],\n",
    "            uncertainty_policy=config['uncertainty_policy'],\n",
    "            train=True,\n",
    "            resize_shape=config['resize'])\n",
    "\n",
    "        val_dataset = CheXpertDataset(\n",
    "            data_path=config['data_path'],\n",
    "            uncertainty_policy=config['uncertainty_policy'],\n",
    "            train=False,\n",
    "            resize_shape=config['resize'])\n",
    "\n",
    "        num_labels = 15 if config['uncertainty_policy'] == 'U-MultiClass' else 5\n",
    "\n",
    "        model = ViTForImageClassification.from_pretrained(\n",
    "            config['checkpoint'], \n",
    "            problem_type=\"multi_label_classification\",\n",
    "            num_labels=num_labels,\n",
    "            ignore_mismatched_sizes=True\n",
    "        ).to(device)\n",
    "\n",
    "        training_args = TrainingArguments(\n",
    "                output_dir=f\"./output/25092023/{config['checkpoint']}/{config['uncertainty_policy']}\",\n",
    "                report_to='wandb',  # Turn on Weights & Biases logging\n",
    "                save_strategy='steps',\n",
    "                save_steps=0.05,\n",
    "                evaluation_strategy=\"epoch\",\n",
    "                logging_strategy='steps',\n",
    "                logging_steps=1,\n",
    "                optim='adamw_torch',\n",
    "                num_train_epochs=config['epochs'],\n",
    "                learning_rate=config['learning_rate'],\n",
    "                lr_scheduler_type='linear',\n",
    "                warmup_steps=1_000,\n",
    "                max_grad_norm=1.0,\n",
    "                per_device_train_batch_size=config['batch_size'],\n",
    "                gradient_accumulation_steps=config['gradient_accumulation'],\n",
    "                weight_decay=0.1,\n",
    "                # gradient_checkpointing=True,\n",
    "                auto_find_batch_size=False,\n",
    "                fp16=True,\n",
    "                dataloader_drop_last=True,\n",
    "                #load_best_model_at_end=True,\n",
    "                push_to_hub=True,\n",
    "                hub_strategy='checkpoint',\n",
    "                hub_private_repo=False,\n",
    "                hub_model_id=f\"lucascruz/CheXpert-ViT-{config['uncertainty_policy']}\",\n",
    "            )\n",
    "\n",
    "        if config['uncertainty_policy'] == 'U-Ignore':\n",
    "            trainer = MaskedLossTrainer(\n",
    "                model=model,\n",
    "                args=training_args,\n",
    "                train_dataset=train_dataset,\n",
    "                eval_dataset=val_dataset,\n",
    "                compute_metrics=compute_metrics,\n",
    "                )\n",
    "        elif config['uncertainty_policy'] == 'U-MultiClass':\n",
    "            trainer = MultiOutputTrainer(\n",
    "                model=model,\n",
    "                args=training_args,\n",
    "                train_dataset=train_dataset,\n",
    "                eval_dataset=val_dataset,\n",
    "                compute_metrics=compute_metrics,\n",
    "                )\n",
    "        else:\n",
    "            trainer = Trainer(\n",
    "                    model=model,\n",
    "                    args=training_args,\n",
    "                    train_dataset=train_dataset,\n",
    "                    eval_dataset=val_dataset,\n",
    "                    compute_metrics=compute_metrics,\n",
    "                )\n",
    "\n",
    "        train_results = trainer.train()\n",
    "        # trainer.save_model(f'{config[\"job_dir\"]}/{config[\"uncertainty_policy\"]}/model_output')\n",
    "\n",
    "        trainer.log_metrics(\"train\", train_results.metrics)\n",
    "        trainer.save_metrics(\"train\", train_results.metrics)\n",
    "        trainer.save_state()\n",
    "\n",
    "        metrics = trainer.evaluate()\n",
    "        # some nice to haves:\n",
    "        trainer.log_metrics(\"eval\", metrics)\n",
    "        trainer.save_metrics(\"eval\", metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.15.12 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\hurbl\\OneDrive\\Área de Trabalho\\Loon Factory\\repository\\Chest-X-Ray-Pathology-Classifier\\notebooks\\wandb\\run-20231007_093230-6ndxhezl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/lucascruz/chexpert-vit/runs/6ndxhezl' target=\"_blank\">U-MultiClass07102023_093230</a></strong> to <a href='https://wandb.ai/lucascruz/chexpert-vit' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/lucascruz/chexpert-vit' target=\"_blank\">https://wandb.ai/lucascruz/chexpert-vit</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/lucascruz/chexpert-vit/runs/6ndxhezl' target=\"_blank\">https://wandb.ai/lucascruz/chexpert-vit/runs/6ndxhezl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-07 09:32:31,358 - __main__ - INFO - Local database found.\n",
      "2023-10-07 09:32:31,742 - __main__ - INFO - Local database found.\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([15, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([15]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\hurbl\\OneDrive\\Área de Trabalho\\Loon Factory\\repository\\Chest-X-Ray-Pathology-Classifier\\notebooks\\./output/25092023/google/vit-base-patch16-224/U-MultiClass is already a clone of https://huggingface.co/lucascruz/CheXpert-ViT-U-MultiClass. Make sure you pull the latest changes with `repo.git_pull()`.\n",
      "2023-10-07 09:32:33,518 - huggingface_hub.repository - WARNING - c:\\Users\\hurbl\\OneDrive\\Área de Trabalho\\Loon Factory\\repository\\Chest-X-Ray-Pathology-Classifier\\notebooks\\./output/25092023/google/vit-base-patch16-224/U-MultiClass is already a clone of https://huggingface.co/lucascruz/CheXpert-ViT-U-MultiClass. Make sure you pull the latest changes with `repo.git_pull()`.\n",
      "                                             \n",
      "\n",
      "\n",
      "c:\\Users\\hurbl\\OneDrive\\Área de Trabalho\\Loon Factory\\repository\\Chest-X-Ray-Pathology-Classifier\\.env\\Lib\\site-packages\\wandb\\sdk\\wandb_run.py:2088: UserWarning: Run (nh4sjr62) is finished. The call to `_console_raw_callback` will be ignored. Please make sure that you are using an active run.\n",
      "  def wrap_fallback() -> None:\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\n",
      " 20%|██        | 1/5 [00:00<00:02,  1.71it/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0396, 'learning_rate': 4.0000000000000003e-07, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hurbl\\OneDrive\\Área de Trabalho\\Loon Factory\\repository\\Chest-X-Ray-Pathology-Classifier\\.env\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\hurbl\\OneDrive\\Área de Trabalho\\Loon Factory\\repository\\Chest-X-Ray-Pathology-Classifier\\.env\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "c:\\Users\\hurbl\\OneDrive\\Área de Trabalho\\Loon Factory\\repository\\Chest-X-Ray-Pathology-Classifier\\.env\\Lib\\site-packages\\wandb\\sdk\\wandb_run.py:2088: UserWarning: Run (nh4sjr62) is finished. The call to `_console_raw_callback` will be ignored. Please make sure that you are using an active run.\n",
      "  def wrap_fallback() -> None:\n",
      "\u001b[A\u001b[A\u001b[A                                     \n",
      "\n",
      " 20%|██        | 1/5 [00:15<00:02,  1.71it/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3038330078125, 'eval_auc_roc_mean': 0.31190475821495056, 'eval_f1_mean': 0.2030014544725418, 'eval_acc_mean': 0.2825396955013275, 'eval_runtime': 0.5405, 'eval_samples_per_second': 18.501, 'eval_steps_per_second': 3.7, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                                     \n",
      "\n",
      " 40%|████      | 2/5 [00:15<00:27,  9.08s/it]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.039, 'learning_rate': 8.000000000000001e-07, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hurbl\\OneDrive\\Área de Trabalho\\Loon Factory\\repository\\Chest-X-Ray-Pathology-Classifier\\.env\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\hurbl\\OneDrive\\Área de Trabalho\\Loon Factory\\repository\\Chest-X-Ray-Pathology-Classifier\\.env\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "c:\\Users\\hurbl\\OneDrive\\Área de Trabalho\\Loon Factory\\repository\\Chest-X-Ray-Pathology-Classifier\\.env\\Lib\\site-packages\\wandb\\sdk\\wandb_run.py:2088: UserWarning: Run (nh4sjr62) is finished. The call to `_console_raw_callback` will be ignored. Please make sure that you are using an active run.\n",
      "  def wrap_fallback() -> None:\n",
      "\u001b[A\u001b[A\u001b[A                                     \n",
      "\n",
      " 40%|████      | 2/5 [00:16<00:27,  9.08s/it]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.299218773841858, 'eval_auc_roc_mean': 0.31190475821495056, 'eval_f1_mean': 0.2030014544725418, 'eval_acc_mean': 0.2825396955013275, 'eval_runtime': 0.3271, 'eval_samples_per_second': 30.572, 'eval_steps_per_second': 6.114, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                                     \n",
      "\n",
      " 60%|██████    | 3/5 [00:17<00:11,  5.69s/it]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0399, 'learning_rate': 1.2000000000000002e-06, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hurbl\\OneDrive\\Área de Trabalho\\Loon Factory\\repository\\Chest-X-Ray-Pathology-Classifier\\.env\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\hurbl\\OneDrive\\Área de Trabalho\\Loon Factory\\repository\\Chest-X-Ray-Pathology-Classifier\\.env\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "c:\\Users\\hurbl\\OneDrive\\Área de Trabalho\\Loon Factory\\repository\\Chest-X-Ray-Pathology-Classifier\\.env\\Lib\\site-packages\\wandb\\sdk\\wandb_run.py:2088: UserWarning: Run (nh4sjr62) is finished. The call to `_console_raw_callback` will be ignored. Please make sure that you are using an active run.\n",
      "  def wrap_fallback() -> None:\n",
      "\u001b[A\u001b[A\u001b[A                                     \n",
      "\n",
      " 60%|██████    | 3/5 [01:01<00:11,  5.69s/it]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2904175519943237, 'eval_auc_roc_mean': 0.3063492178916931, 'eval_f1_mean': 0.2030014544725418, 'eval_acc_mean': 0.2825396955013275, 'eval_runtime': 0.5829, 'eval_samples_per_second': 17.156, 'eval_steps_per_second': 3.431, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                                     \n",
      "\n",
      " 80%|████████  | 4/5 [01:01<00:21, 21.09s/it]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0386, 'learning_rate': 1.6000000000000001e-06, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hurbl\\OneDrive\\Área de Trabalho\\Loon Factory\\repository\\Chest-X-Ray-Pathology-Classifier\\.env\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\hurbl\\OneDrive\\Área de Trabalho\\Loon Factory\\repository\\Chest-X-Ray-Pathology-Classifier\\.env\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "c:\\Users\\hurbl\\OneDrive\\Área de Trabalho\\Loon Factory\\repository\\Chest-X-Ray-Pathology-Classifier\\.env\\Lib\\site-packages\\wandb\\sdk\\wandb_run.py:2088: UserWarning: Run (nh4sjr62) is finished. The call to `_console_raw_callback` will be ignored. Please make sure that you are using an active run.\n",
      "  def wrap_fallback() -> None:\n",
      "\u001b[A\u001b[A\u001b[A                                     \n",
      "\n",
      " 80%|████████  | 4/5 [01:03<00:21, 21.09s/it]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2769348621368408, 'eval_auc_roc_mean': 0.3063492178916931, 'eval_f1_mean': 0.2030014544725418, 'eval_acc_mean': 0.2825396955013275, 'eval_runtime': 0.3384, 'eval_samples_per_second': 29.552, 'eval_steps_per_second': 5.91, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                                     \n",
      "\n",
      "100%|██████████| 5/5 [01:03<00:00, 14.13s/it]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0393, 'learning_rate': 2.0000000000000003e-06, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hurbl\\OneDrive\\Área de Trabalho\\Loon Factory\\repository\\Chest-X-Ray-Pathology-Classifier\\.env\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\hurbl\\OneDrive\\Área de Trabalho\\Loon Factory\\repository\\Chest-X-Ray-Pathology-Classifier\\.env\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "c:\\Users\\hurbl\\OneDrive\\Área de Trabalho\\Loon Factory\\repository\\Chest-X-Ray-Pathology-Classifier\\.env\\Lib\\site-packages\\wandb\\sdk\\wandb_run.py:2088: UserWarning: Run (nh4sjr62) is finished. The call to `_console_raw_callback` will be ignored. Please make sure that you are using an active run.\n",
      "  def wrap_fallback() -> None:\n",
      "\u001b[A\u001b[A\u001b[A                                     \n",
      "\n",
      "100%|██████████| 5/5 [01:05<00:00, 14.13s/it]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                                     \n",
      "\n",
      "100%|██████████| 5/5 [01:05<00:00, 14.13s/it]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2586853504180908, 'eval_auc_roc_mean': 0.3063492178916931, 'eval_f1_mean': 0.17229436337947845, 'eval_acc_mean': 0.21587303280830383, 'eval_runtime': 0.3887, 'eval_samples_per_second': 25.73, 'eval_steps_per_second': 5.146, 'epoch': 5.0}\n",
      "{'train_runtime': 65.303, 'train_samples_per_second': 0.766, 'train_steps_per_second': 0.077, 'train_loss': 0.03927242383360863, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hurbl\\OneDrive\\Área de Trabalho\\Loon Factory\\repository\\Chest-X-Ray-Pathology-Classifier\\notebooks\\./output/25092023/google/vit-base-patch16-224/U-MultiClass is already a clone of https://huggingface.co/lucascruz/CheXpert-ViT-U-MultiClass. Make sure you pull the latest changes with `repo.git_pull()`.\n",
      "2023-10-07 09:33:42,009 - huggingface_hub.repository - WARNING - c:\\Users\\hurbl\\OneDrive\\Área de Trabalho\\Loon Factory\\repository\\Chest-X-Ray-Pathology-Classifier\\notebooks\\./output/25092023/google/vit-base-patch16-224/U-MultiClass is already a clone of https://huggingface.co/lucascruz/CheXpert-ViT-U-MultiClass. Make sure you pull the latest changes with `repo.git_pull()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Ctrl-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/acc_mean</td><td>████▁</td></tr><tr><td>eval/auc_roc_mean</td><td>██▁▁▁</td></tr><tr><td>eval/f1_mean</td><td>████▁</td></tr><tr><td>eval/loss</td><td>█▇▆▄▁</td></tr><tr><td>eval/runtime</td><td>▇▁█▁▃</td></tr><tr><td>eval/samples_per_second</td><td>▂█▁▇▅</td></tr><tr><td>eval/steps_per_second</td><td>▂█▁▇▅</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▅▅▆▆███</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▅▅▆▆███</td></tr><tr><td>train/learning_rate</td><td>▁▃▅▆█</td></tr><tr><td>train/loss</td><td>▆▃█▁▅</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/acc_mean</td><td>0.21587</td></tr><tr><td>eval/auc_roc_mean</td><td>0.30635</td></tr><tr><td>eval/f1_mean</td><td>0.17229</td></tr><tr><td>eval/loss</td><td>1.25869</td></tr><tr><td>eval/runtime</td><td>0.3887</td></tr><tr><td>eval/samples_per_second</td><td>25.73</td></tr><tr><td>eval/steps_per_second</td><td>5.146</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>5</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0393</td></tr><tr><td>train/total_flos</td><td>3100040743403520.0</td></tr><tr><td>train/train_loss</td><td>0.03927</td></tr><tr><td>train/train_runtime</td><td>65.303</td></tr><tr><td>train/train_samples_per_second</td><td>0.766</td></tr><tr><td>train/train_steps_per_second</td><td>0.077</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">U-MultiClass07102023_093230</strong> at: <a href='https://wandb.ai/lucascruz/chexpert-vit/runs/6ndxhezl' target=\"_blank\">https://wandb.ai/lucascruz/chexpert-vit/runs/6ndxhezl</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231007_093230-6ndxhezl\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[83], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m sys\u001b[39m.\u001b[39margv \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      8\u001b[0m args \u001b[39m=\u001b[39m get_args()\n\u001b[1;32m----> 9\u001b[0m main(args)\n",
      "Cell \u001b[1;32mIn[82], line 266\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    258\u001b[0m     trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[0;32m    259\u001b[0m             model\u001b[39m=\u001b[39mmodel,\n\u001b[0;32m    260\u001b[0m             args\u001b[39m=\u001b[39mtraining_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    263\u001b[0m             compute_metrics\u001b[39m=\u001b[39mcompute_metrics,\n\u001b[0;32m    264\u001b[0m         )\n\u001b[1;32m--> 266\u001b[0m train_results \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mtrain()\n\u001b[0;32m    267\u001b[0m \u001b[39m# trainer.save_model(f'{config[\"job_dir\"]}/{config[\"uncertainty_policy\"]}/model_output')\u001b[39;00m\n\u001b[0;32m    269\u001b[0m trainer\u001b[39m.\u001b[39mlog_metrics(\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m, train_results\u001b[39m.\u001b[39mmetrics)\n",
      "File \u001b[1;32mc:\\Users\\hurbl\\OneDrive\\Área de Trabalho\\Loon Factory\\repository\\Chest-X-Ray-Pathology-Classifier\\.env\\Lib\\site-packages\\transformers\\trainer.py:1664\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[0;32m   1661\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[0;32m   1662\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[0;32m   1663\u001b[0m )\n\u001b[1;32m-> 1664\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[0;32m   1665\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m   1666\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[0;32m   1667\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[0;32m   1668\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[0;32m   1669\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\hurbl\\OneDrive\\Área de Trabalho\\Loon Factory\\repository\\Chest-X-Ray-Pathology-Classifier\\.env\\Lib\\site-packages\\transformers\\trainer.py:2089\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2086\u001b[0m             logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDeleting older checkpoint [\u001b[39m\u001b[39m{\u001b[39;00mcheckpoint\u001b[39m}\u001b[39;00m\u001b[39m] due to args.save_total_limit\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   2087\u001b[0m             shutil\u001b[39m.\u001b[39mrmtree(checkpoint)\n\u001b[1;32m-> 2089\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcallback_handler\u001b[39m.\u001b[39;49mon_train_end(args, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstate, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcontrol)\n\u001b[0;32m   2091\u001b[0m \u001b[39mreturn\u001b[39;00m TrainOutput(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step, train_loss, metrics)\n",
      "File \u001b[1;32mc:\\Users\\hurbl\\OneDrive\\Área de Trabalho\\Loon Factory\\repository\\Chest-X-Ray-Pathology-Classifier\\.env\\Lib\\site-packages\\transformers\\trainer_callback.py:356\u001b[0m, in \u001b[0;36mCallbackHandler.on_train_end\u001b[1;34m(self, args, state, control)\u001b[0m\n\u001b[0;32m    355\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_train_end\u001b[39m(\u001b[39mself\u001b[39m, args: TrainingArguments, state: TrainerState, control: TrainerControl):\n\u001b[1;32m--> 356\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcall_event(\u001b[39m\"\u001b[39;49m\u001b[39mon_train_end\u001b[39;49m\u001b[39m\"\u001b[39;49m, args, state, control)\n",
      "File \u001b[1;32mc:\\Users\\hurbl\\OneDrive\\Área de Trabalho\\Loon Factory\\repository\\Chest-X-Ray-Pathology-Classifier\\.env\\Lib\\site-packages\\transformers\\trainer_callback.py:397\u001b[0m, in \u001b[0;36mCallbackHandler.call_event\u001b[1;34m(self, event, args, state, control, **kwargs)\u001b[0m\n\u001b[0;32m    395\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall_event\u001b[39m(\u001b[39mself\u001b[39m, event, args, state, control, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    396\u001b[0m     \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[1;32m--> 397\u001b[0m         result \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(callback, event)(\n\u001b[0;32m    398\u001b[0m             args,\n\u001b[0;32m    399\u001b[0m             state,\n\u001b[0;32m    400\u001b[0m             control,\n\u001b[0;32m    401\u001b[0m             model\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel,\n\u001b[0;32m    402\u001b[0m             tokenizer\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtokenizer,\n\u001b[0;32m    403\u001b[0m             optimizer\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer,\n\u001b[0;32m    404\u001b[0m             lr_scheduler\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlr_scheduler,\n\u001b[0;32m    405\u001b[0m             train_dataloader\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_dataloader,\n\u001b[0;32m    406\u001b[0m             eval_dataloader\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meval_dataloader,\n\u001b[0;32m    407\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m    408\u001b[0m         )\n\u001b[0;32m    409\u001b[0m         \u001b[39m# A Callback can skip the return of `control` if it doesn't change it.\u001b[39;00m\n\u001b[0;32m    410\u001b[0m         \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\hurbl\\OneDrive\\Área de Trabalho\\Loon Factory\\repository\\Chest-X-Ray-Pathology-Classifier\\.env\\Lib\\site-packages\\transformers\\integrations.py:774\u001b[0m, in \u001b[0;36mWandbCallback.on_train_end\u001b[1;34m(self, args, state, control, model, tokenizer, **kwargs)\u001b[0m\n\u001b[0;32m    772\u001b[0m fake_trainer \u001b[39m=\u001b[39m Trainer(args\u001b[39m=\u001b[39margs, model\u001b[39m=\u001b[39mmodel, tokenizer\u001b[39m=\u001b[39mtokenizer)\n\u001b[0;32m    773\u001b[0m \u001b[39mwith\u001b[39;00m tempfile\u001b[39m.\u001b[39mTemporaryDirectory() \u001b[39mas\u001b[39;00m temp_dir:\n\u001b[1;32m--> 774\u001b[0m     fake_trainer\u001b[39m.\u001b[39;49msave_model(temp_dir)\n\u001b[0;32m    775\u001b[0m     metadata \u001b[39m=\u001b[39m (\n\u001b[0;32m    776\u001b[0m         {\n\u001b[0;32m    777\u001b[0m             k: v\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    785\u001b[0m         }\n\u001b[0;32m    786\u001b[0m     )\n\u001b[0;32m    787\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mLogging model artifacts. ...\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\hurbl\\OneDrive\\Área de Trabalho\\Loon Factory\\repository\\Chest-X-Ray-Pathology-Classifier\\.env\\Lib\\site-packages\\transformers\\trainer.py:2870\u001b[0m, in \u001b[0;36mTrainer.save_model\u001b[1;34m(self, output_dir, _internal_call)\u001b[0m\n\u001b[0;32m   2868\u001b[0m \u001b[39m# Push to the Hub when `save_model` is called by the user.\u001b[39;00m\n\u001b[0;32m   2869\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mpush_to_hub \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m _internal_call:\n\u001b[1;32m-> 2870\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpush_to_hub(commit_message\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mModel save\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\hurbl\\OneDrive\\Área de Trabalho\\Loon Factory\\repository\\Chest-X-Ray-Pathology-Classifier\\.env\\Lib\\site-packages\\transformers\\trainer.py:3698\u001b[0m, in \u001b[0;36mTrainer.push_to_hub\u001b[1;34m(self, commit_message, blocking, **kwargs)\u001b[0m\n\u001b[0;32m   3695\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpush_in_progress\u001b[39m.\u001b[39m_process\u001b[39m.\u001b[39mkill()\n\u001b[0;32m   3696\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpush_in_progress \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 3698\u001b[0m git_head_commit_url \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrepo\u001b[39m.\u001b[39;49mpush_to_hub(\n\u001b[0;32m   3699\u001b[0m     commit_message\u001b[39m=\u001b[39;49mcommit_message, blocking\u001b[39m=\u001b[39;49mblocking, auto_lfs_prune\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[0;32m   3700\u001b[0m )\n\u001b[0;32m   3701\u001b[0m \u001b[39m# push separately the model card to be independant from the rest of the model\u001b[39;00m\n\u001b[0;32m   3702\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mshould_save:\n",
      "File \u001b[1;32mc:\\Users\\hurbl\\OneDrive\\Área de Trabalho\\Loon Factory\\repository\\Chest-X-Ray-Pathology-Classifier\\.env\\Lib\\site-packages\\huggingface_hub\\repository.py:1304\u001b[0m, in \u001b[0;36mRepository.push_to_hub\u001b[1;34m(self, commit_message, blocking, clean_ok, auto_lfs_prune)\u001b[0m\n\u001b[0;32m   1302\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mRepo currently clean. Ignoring push_to_hub\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1303\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1304\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgit_add(auto_lfs_track\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m   1305\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgit_commit(commit_message)\n\u001b[0;32m   1306\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgit_push(\n\u001b[0;32m   1307\u001b[0m     upstream\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39morigin \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_branch\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1308\u001b[0m     blocking\u001b[39m=\u001b[39mblocking,\n\u001b[0;32m   1309\u001b[0m     auto_lfs_prune\u001b[39m=\u001b[39mauto_lfs_prune,\n\u001b[0;32m   1310\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\hurbl\\OneDrive\\Área de Trabalho\\Loon Factory\\repository\\Chest-X-Ray-Pathology-Classifier\\.env\\Lib\\site-packages\\huggingface_hub\\repository.py:1017\u001b[0m, in \u001b[0;36mRepository.git_add\u001b[1;34m(self, pattern, auto_lfs_track)\u001b[0m\n\u001b[0;32m   1011\u001b[0m         logger\u001b[39m.\u001b[39mwarning(\n\u001b[0;32m   1012\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAdding files tracked by Git LFS: \u001b[39m\u001b[39m{\u001b[39;00mtracked_files\u001b[39m}\u001b[39;00m\u001b[39m. This may take a\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1013\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m bit of time if the files are large.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1014\u001b[0m         )\n\u001b[0;32m   1016\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1017\u001b[0m     result \u001b[39m=\u001b[39m run_subprocess(\u001b[39m\"\u001b[39;49m\u001b[39mgit add -v\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49msplit() \u001b[39m+\u001b[39;49m [pattern], \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlocal_dir)\n\u001b[0;32m   1018\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAdding to index:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mresult\u001b[39m.\u001b[39mstdout\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1019\u001b[0m \u001b[39mexcept\u001b[39;00m subprocess\u001b[39m.\u001b[39mCalledProcessError \u001b[39mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\hurbl\\OneDrive\\Área de Trabalho\\Loon Factory\\repository\\Chest-X-Ray-Pathology-Classifier\\.env\\Lib\\site-packages\\huggingface_hub\\utils\\_subprocess.py:83\u001b[0m, in \u001b[0;36mrun_subprocess\u001b[1;34m(command, folder, check, **kwargs)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(folder, Path):\n\u001b[0;32m     81\u001b[0m     folder \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(folder)\n\u001b[1;32m---> 83\u001b[0m \u001b[39mreturn\u001b[39;00m subprocess\u001b[39m.\u001b[39;49mrun(\n\u001b[0;32m     84\u001b[0m     command,\n\u001b[0;32m     85\u001b[0m     stderr\u001b[39m=\u001b[39;49msubprocess\u001b[39m.\u001b[39;49mPIPE,\n\u001b[0;32m     86\u001b[0m     stdout\u001b[39m=\u001b[39;49msubprocess\u001b[39m.\u001b[39;49mPIPE,\n\u001b[0;32m     87\u001b[0m     check\u001b[39m=\u001b[39;49mcheck,\n\u001b[0;32m     88\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     89\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mreplace\u001b[39;49m\u001b[39m\"\u001b[39;49m,  \u001b[39m# if not utf-8, replace char by �\u001b[39;49;00m\n\u001b[0;32m     90\u001b[0m     cwd\u001b[39m=\u001b[39;49mfolder \u001b[39mor\u001b[39;49;00m os\u001b[39m.\u001b[39;49mgetcwd(),\n\u001b[0;32m     91\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m     92\u001b[0m )\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\subprocess.py:550\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m \u001b[39mwith\u001b[39;00m Popen(\u001b[39m*\u001b[39mpopenargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39mas\u001b[39;00m process:\n\u001b[0;32m    549\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 550\u001b[0m         stdout, stderr \u001b[39m=\u001b[39m process\u001b[39m.\u001b[39;49mcommunicate(\u001b[39minput\u001b[39;49m, timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    551\u001b[0m     \u001b[39mexcept\u001b[39;00m TimeoutExpired \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m    552\u001b[0m         process\u001b[39m.\u001b[39mkill()\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\subprocess.py:1207\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[1;34m(self, input, timeout)\u001b[0m\n\u001b[0;32m   1204\u001b[0m     endtime \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1206\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1207\u001b[0m     stdout, stderr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_communicate(\u001b[39minput\u001b[39;49m, endtime, timeout)\n\u001b[0;32m   1208\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1209\u001b[0m     \u001b[39m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[0;32m   1210\u001b[0m     \u001b[39m# See the detailed comment in .wait().\u001b[39;00m\n\u001b[0;32m   1211\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\subprocess.py:1597\u001b[0m, in \u001b[0;36mPopen._communicate\u001b[1;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[0;32m   1593\u001b[0m \u001b[39m# Wait for the reader threads, or time out.  If we time out, the\u001b[39;00m\n\u001b[0;32m   1594\u001b[0m \u001b[39m# threads remain reading and the fds left open in case the user\u001b[39;00m\n\u001b[0;32m   1595\u001b[0m \u001b[39m# calls communicate again.\u001b[39;00m\n\u001b[0;32m   1596\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1597\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstdout_thread\u001b[39m.\u001b[39;49mjoin(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_remaining_time(endtime))\n\u001b[0;32m   1598\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdout_thread\u001b[39m.\u001b[39mis_alive():\n\u001b[0;32m   1599\u001b[0m         \u001b[39mraise\u001b[39;00m TimeoutExpired(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, orig_timeout)\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\threading.py:1112\u001b[0m, in \u001b[0;36mThread.join\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1109\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcannot join current thread\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1111\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1112\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wait_for_tstate_lock()\n\u001b[0;32m   1113\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1114\u001b[0m     \u001b[39m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[0;32m   1115\u001b[0m     \u001b[39m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[0;32m   1116\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[39m=\u001b[39m\u001b[39mmax\u001b[39m(timeout, \u001b[39m0\u001b[39m))\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\threading.py:1132\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m   1129\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1132\u001b[0m     \u001b[39mif\u001b[39;00m lock\u001b[39m.\u001b[39;49macquire(block, timeout):\n\u001b[0;32m   1133\u001b[0m         lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m   1134\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stop()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    project_name = \"chexpert-vit\"\n",
    "    os.environ[\"WANDB_PROJECT\"] = project_name\n",
    "    os.environ[\"WANDB_LOG_MODEL\"] = \"true\"\n",
    "\n",
    "    import sys\n",
    "    sys.argv = ['']\n",
    "    args = get_args()\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r\"C:/Users/hurbl/OneDrive/Área de Trabalho/Loon Factory/repository/Chest-X-Ray-Pathology-Classifier/data/raw/\"\n",
    "\n",
    "train_dataset = CheXpertDataset(\n",
    "    data_path=data_path,\n",
    "    uncertainty_policy=\"U-MultiClass\",\n",
    "    train=True,\n",
    "    resize_shape=(224, 224))\n",
    "\n",
    "\n",
    "val_dataset = CheXpertDataset(\n",
    "    data_path=data_path,\n",
    "    uncertainty_policy=\"U-MultiClass\",\n",
    "    train=False,\n",
    "    resize_shape=(224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import ViTForImageClassification\n",
    "\n",
    "model = ViTForImageClassification.from_pretrained(\n",
    "    \"google/vit-base-patch16-224\", \n",
    "    problem_type=\"multi_label_classification\",\n",
    "    num_labels=5,\n",
    "    ignore_mismatched_sizes=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "from transformers import AutoModelForImageClassification, TrainingArguments, Trainer\n",
    "\n",
    "METRICS = evaluate.combine([\"accuracy\", \"f1\", \"precision\", \"recall\"])\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return METRICS.compute(predictions=predictions, references=labels)\n",
    "\n",
    "\n",
    "args = TrainingArguments(\n",
    "    f\"vit_xray\",\n",
    "    remove_unused_columns=False,\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    optim='adamw_torch',\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    gradient_accumulation_steps=4,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "  0%|          | 0/10473 [06:14<?, ?it/s]\n",
      "  0%|          | 0/10473 [04:37<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1 train_results = trainer.train()                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3 #trainer.save_model()</span>                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4 #trainer.log_metrics(\"train\", train_results.metrics)</span>                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/lucas/Projects/x-ray/Chest-X-Ray-Pathology-Classifier/env/lib/python3.8/site-packages/tran</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">sformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1664</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train</span>                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1661 │   │   </span>inner_training_loop = find_executable_batch_size(                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1662 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._inner_training_loop, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._train_batch_size, args.auto_find_batch_size  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1663 │   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1664 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> inner_training_loop(                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1665 │   │   │   </span>args=args,                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1666 │   │   │   </span>resume_from_checkpoint=resume_from_checkpoint,                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1667 │   │   │   </span>trial=trial,                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/lucas/Projects/x-ray/Chest-X-Ray-Pathology-Classifier/env/lib/python3.8/site-packages/tran</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">sformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1940</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_inner_training_loop</span>                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1937 │   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> model.no_sync():                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1938 │   │   │   │   │   │   </span>tr_loss_step = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.training_step(model, inputs)                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1939 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1940 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>tr_loss_step = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.training_step(model, inputs)                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1941 │   │   │   │   </span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1942 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> (                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1943 │   │   │   │   │   </span>args.logging_nan_inf_filter                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/lucas/Projects/x-ray/Chest-X-Ray-Pathology-Classifier/env/lib/python3.8/site-packages/tran</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">sformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2735</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">training_step</span>                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2732 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> loss_mb.reduce_mean().detach().to(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.args.device)                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2733 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2734 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.compute_loss_context_manager():                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2735 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>loss = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.compute_loss(model, inputs)                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2736 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2737 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.args.n_gpu &gt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>:                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2738 │   │   │   </span>loss = loss.mean()  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># mean() to average on multi-gpu parallel training</span>        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/lucas/Projects/x-ray/Chest-X-Ray-Pathology-Classifier/env/lib/python3.8/site-packages/tran</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">sformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2767</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">compute_loss</span>                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2764 │   │   │   </span>labels = inputs.pop(<span style=\"color: #808000; text-decoration-color: #808000\">\"labels\"</span>)                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2765 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2766 │   │   │   </span>labels = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2767 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>outputs = model(**inputs)                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2768 │   │   # Save past state if it exists</span>                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2769 │   │   # TODO: this needs to be fixed and made cleaner later.</span>                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2770 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.args.past_index &gt;= <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>:                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/lucas/Projects/x-ray/Chest-X-Ray-Pathology-Classifier/env/lib/python3.8/site-packages/torc</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">h/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 │   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/lucas/Projects/x-ray/Chest-X-Ray-Pathology-Classifier/env/lib/python3.8/site-packages/tran</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">sformers/models/vit/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_vit.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">797</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">794 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">795 │   │   </span>return_dict = return_dict <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> return_dict <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.config.use_return   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">796 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>797 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>outputs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.vit(                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">798 │   │   │   </span>pixel_values,                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">799 │   │   │   </span>head_mask=head_mask,                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">800 │   │   │   </span>output_attentions=output_attentions,                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/lucas/Projects/x-ray/Chest-X-Ray-Pathology-Classifier/env/lib/python3.8/site-packages/torc</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">h/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 │   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/lucas/Projects/x-ray/Chest-X-Ray-Pathology-Classifier/env/lib/python3.8/site-packages/tran</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">sformers/models/vit/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_vit.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">587</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">584 │   │   │   </span>pixel_values, bool_masked_pos=bool_masked_pos, interpolate_pos_encoding=inte   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">585 │   │   </span>)                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">586 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>587 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>encoder_outputs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.encoder(                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">588 │   │   │   </span>embedding_output,                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">589 │   │   │   </span>head_mask=head_mask,                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">590 │   │   │   </span>output_attentions=output_attentions,                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/lucas/Projects/x-ray/Chest-X-Ray-Pathology-Classifier/env/lib/python3.8/site-packages/torc</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">h/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 │   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/lucas/Projects/x-ray/Chest-X-Ray-Pathology-Classifier/env/lib/python3.8/site-packages/tran</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">sformers/models/vit/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_vit.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">413</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">410 │   │   │   │   │   </span>layer_head_mask,                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">411 │   │   │   │   </span>)                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">412 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>413 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>layer_outputs = layer_module(hidden_states, layer_head_mask, output_atte   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">414 │   │   │   </span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">415 │   │   │   </span>hidden_states = layer_outputs[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>]                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">416 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/lucas/Projects/x-ray/Chest-X-Ray-Pathology-Classifier/env/lib/python3.8/site-packages/torc</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">h/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 │   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/lucas/Projects/x-ray/Chest-X-Ray-Pathology-Classifier/env/lib/python3.8/site-packages/tran</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">sformers/models/vit/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_vit.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">352</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">349 │   │   </span>head_mask: Optional[torch.Tensor] = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>,                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">350 │   │   </span>output_attentions: <span style=\"color: #00ffff; text-decoration-color: #00ffff\">bool</span> = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>,                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">351 │   </span>) -&gt; Union[Tuple[torch.Tensor, torch.Tensor], Tuple[torch.Tensor]]:                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>352 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>self_attention_outputs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.attention(                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">353 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.layernorm_before(hidden_states),  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># in ViT, layernorm is applied before</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">354 │   │   │   </span>head_mask,                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">355 │   │   │   </span>output_attentions=output_attentions,                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/lucas/Projects/x-ray/Chest-X-Ray-Pathology-Classifier/env/lib/python3.8/site-packages/torc</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">h/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 │   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/lucas/Projects/x-ray/Chest-X-Ray-Pathology-Classifier/env/lib/python3.8/site-packages/tran</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">sformers/models/vit/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_vit.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">294</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">291 │   │   </span>head_mask: Optional[torch.Tensor] = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>,                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">292 │   │   </span>output_attentions: <span style=\"color: #00ffff; text-decoration-color: #00ffff\">bool</span> = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>,                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">293 │   </span>) -&gt; Union[Tuple[torch.Tensor, torch.Tensor], Tuple[torch.Tensor]]:                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>294 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>self_outputs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.attention(hidden_states, head_mask, output_attentions)         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">295 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">296 │   │   </span>attention_output = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.output(self_outputs[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>], hidden_states)                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">297 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/lucas/Projects/x-ray/Chest-X-Ray-Pathology-Classifier/env/lib/python3.8/site-packages/torc</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">h/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 │   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/lucas/Projects/x-ray/Chest-X-Ray-Pathology-Classifier/env/lib/python3.8/site-packages/tran</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">sformers/models/vit/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_vit.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">236</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">233 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">234 │   │   </span>context_layer = torch.matmul(attention_probs, value_layer)                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">235 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>236 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>context_layer = context_layer.permute(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span>).contiguous()                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">237 │   │   </span>new_context_layer_shape = context_layer.size()[:-<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>] + (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.all_head_size,)        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">238 │   │   </span>context_layer = context_layer.view(new_context_layer_shape)                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">239 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">OutOfMemoryError: </span>CUDA out of memory. Tried to allocate <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20.00</span> MiB <span style=\"font-weight: bold\">(</span>GPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.80</span> GiB total capacity; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.82</span> GiB already\n",
       "allocated; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">44.75</span> MiB free; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.06</span> GiB reserved in total by PyTorch<span style=\"font-weight: bold\">)</span> If reserved memory is &gt;&gt; allocated memory try \n",
       "setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and \n",
       "PYTORCH_CUDA_ALLOC_CONF\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1 train_results = trainer.train()                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3 \u001b[0m\u001b[2m#trainer.save_model()\u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m4 \u001b[0m\u001b[2m#trainer.log_metrics(\"train\", train_results.metrics)\u001b[0m                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/lucas/Projects/x-ray/Chest-X-Ray-Pathology-Classifier/env/lib/python3.8/site-packages/tran\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33msformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m1664\u001b[0m in \u001b[92mtrain\u001b[0m                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1661 \u001b[0m\u001b[2m│   │   \u001b[0minner_training_loop = find_executable_batch_size(                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1662 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._inner_training_loop, \u001b[96mself\u001b[0m._train_batch_size, args.auto_find_batch_size  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1663 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1664 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m inner_training_loop(                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1665 \u001b[0m\u001b[2m│   │   │   \u001b[0margs=args,                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1666 \u001b[0m\u001b[2m│   │   │   \u001b[0mresume_from_checkpoint=resume_from_checkpoint,                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1667 \u001b[0m\u001b[2m│   │   │   \u001b[0mtrial=trial,                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/lucas/Projects/x-ray/Chest-X-Ray-Pathology-Classifier/env/lib/python3.8/site-packages/tran\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33msformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m1940\u001b[0m in \u001b[92m_inner_training_loop\u001b[0m                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1937 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mwith\u001b[0m model.no_sync():                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1938 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0mtr_loss_step = \u001b[96mself\u001b[0m.training_step(model, inputs)                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1939 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1940 \u001b[2m│   │   │   │   │   \u001b[0mtr_loss_step = \u001b[96mself\u001b[0m.training_step(model, inputs)                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1941 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1942 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m (                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1943 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0margs.logging_nan_inf_filter                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/lucas/Projects/x-ray/Chest-X-Ray-Pathology-Classifier/env/lib/python3.8/site-packages/tran\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33msformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m2735\u001b[0m in \u001b[92mtraining_step\u001b[0m                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2732 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m loss_mb.reduce_mean().detach().to(\u001b[96mself\u001b[0m.args.device)                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2733 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2734 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mwith\u001b[0m \u001b[96mself\u001b[0m.compute_loss_context_manager():                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2735 \u001b[2m│   │   │   \u001b[0mloss = \u001b[96mself\u001b[0m.compute_loss(model, inputs)                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2736 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2737 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.args.n_gpu > \u001b[94m1\u001b[0m:                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2738 \u001b[0m\u001b[2m│   │   │   \u001b[0mloss = loss.mean()  \u001b[2m# mean() to average on multi-gpu parallel training\u001b[0m        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/lucas/Projects/x-ray/Chest-X-Ray-Pathology-Classifier/env/lib/python3.8/site-packages/tran\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33msformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m2767\u001b[0m in \u001b[92mcompute_loss\u001b[0m                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2764 \u001b[0m\u001b[2m│   │   │   \u001b[0mlabels = inputs.pop(\u001b[33m\"\u001b[0m\u001b[33mlabels\u001b[0m\u001b[33m\"\u001b[0m)                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2765 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2766 \u001b[0m\u001b[2m│   │   │   \u001b[0mlabels = \u001b[94mNone\u001b[0m                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2767 \u001b[2m│   │   \u001b[0moutputs = model(**inputs)                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2768 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Save past state if it exists\u001b[0m                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2769 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# TODO: this needs to be fixed and made cleaner later.\u001b[0m                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2770 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.args.past_index >= \u001b[94m0\u001b[0m:                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/lucas/Projects/x-ray/Chest-X-Ray-Pathology-Classifier/env/lib/python3.8/site-packages/torc\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33mh/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/lucas/Projects/x-ray/Chest-X-Ray-Pathology-Classifier/env/lib/python3.8/site-packages/tran\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33msformers/models/vit/\u001b[0m\u001b[1;33mmodeling_vit.py\u001b[0m:\u001b[94m797\u001b[0m in \u001b[92mforward\u001b[0m                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m794 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m795 \u001b[0m\u001b[2m│   │   \u001b[0mreturn_dict = return_dict \u001b[94mif\u001b[0m return_dict \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[94melse\u001b[0m \u001b[96mself\u001b[0m.config.use_return   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m796 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m797 \u001b[2m│   │   \u001b[0moutputs = \u001b[96mself\u001b[0m.vit(                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m798 \u001b[0m\u001b[2m│   │   │   \u001b[0mpixel_values,                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m799 \u001b[0m\u001b[2m│   │   │   \u001b[0mhead_mask=head_mask,                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m800 \u001b[0m\u001b[2m│   │   │   \u001b[0moutput_attentions=output_attentions,                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/lucas/Projects/x-ray/Chest-X-Ray-Pathology-Classifier/env/lib/python3.8/site-packages/torc\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33mh/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/lucas/Projects/x-ray/Chest-X-Ray-Pathology-Classifier/env/lib/python3.8/site-packages/tran\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33msformers/models/vit/\u001b[0m\u001b[1;33mmodeling_vit.py\u001b[0m:\u001b[94m587\u001b[0m in \u001b[92mforward\u001b[0m                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m584 \u001b[0m\u001b[2m│   │   │   \u001b[0mpixel_values, bool_masked_pos=bool_masked_pos, interpolate_pos_encoding=inte   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m585 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m586 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m587 \u001b[2m│   │   \u001b[0mencoder_outputs = \u001b[96mself\u001b[0m.encoder(                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m588 \u001b[0m\u001b[2m│   │   │   \u001b[0membedding_output,                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m589 \u001b[0m\u001b[2m│   │   │   \u001b[0mhead_mask=head_mask,                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m590 \u001b[0m\u001b[2m│   │   │   \u001b[0moutput_attentions=output_attentions,                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/lucas/Projects/x-ray/Chest-X-Ray-Pathology-Classifier/env/lib/python3.8/site-packages/torc\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33mh/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/lucas/Projects/x-ray/Chest-X-Ray-Pathology-Classifier/env/lib/python3.8/site-packages/tran\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33msformers/models/vit/\u001b[0m\u001b[1;33mmodeling_vit.py\u001b[0m:\u001b[94m413\u001b[0m in \u001b[92mforward\u001b[0m                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m410 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mlayer_head_mask,                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m411 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m)                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m412 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m413 \u001b[2m│   │   │   │   \u001b[0mlayer_outputs = layer_module(hidden_states, layer_head_mask, output_atte   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m414 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m415 \u001b[0m\u001b[2m│   │   │   \u001b[0mhidden_states = layer_outputs[\u001b[94m0\u001b[0m]                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m416 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/lucas/Projects/x-ray/Chest-X-Ray-Pathology-Classifier/env/lib/python3.8/site-packages/torc\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33mh/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/lucas/Projects/x-ray/Chest-X-Ray-Pathology-Classifier/env/lib/python3.8/site-packages/tran\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33msformers/models/vit/\u001b[0m\u001b[1;33mmodeling_vit.py\u001b[0m:\u001b[94m352\u001b[0m in \u001b[92mforward\u001b[0m                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m349 \u001b[0m\u001b[2m│   │   \u001b[0mhead_mask: Optional[torch.Tensor] = \u001b[94mNone\u001b[0m,                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m350 \u001b[0m\u001b[2m│   │   \u001b[0moutput_attentions: \u001b[96mbool\u001b[0m = \u001b[94mFalse\u001b[0m,                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m351 \u001b[0m\u001b[2m│   \u001b[0m) -> Union[Tuple[torch.Tensor, torch.Tensor], Tuple[torch.Tensor]]:                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m352 \u001b[2m│   │   \u001b[0mself_attention_outputs = \u001b[96mself\u001b[0m.attention(                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m353 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.layernorm_before(hidden_states),  \u001b[2m# in ViT, layernorm is applied before\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m354 \u001b[0m\u001b[2m│   │   │   \u001b[0mhead_mask,                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m355 \u001b[0m\u001b[2m│   │   │   \u001b[0moutput_attentions=output_attentions,                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/lucas/Projects/x-ray/Chest-X-Ray-Pathology-Classifier/env/lib/python3.8/site-packages/torc\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33mh/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/lucas/Projects/x-ray/Chest-X-Ray-Pathology-Classifier/env/lib/python3.8/site-packages/tran\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33msformers/models/vit/\u001b[0m\u001b[1;33mmodeling_vit.py\u001b[0m:\u001b[94m294\u001b[0m in \u001b[92mforward\u001b[0m                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m291 \u001b[0m\u001b[2m│   │   \u001b[0mhead_mask: Optional[torch.Tensor] = \u001b[94mNone\u001b[0m,                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m292 \u001b[0m\u001b[2m│   │   \u001b[0moutput_attentions: \u001b[96mbool\u001b[0m = \u001b[94mFalse\u001b[0m,                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m293 \u001b[0m\u001b[2m│   \u001b[0m) -> Union[Tuple[torch.Tensor, torch.Tensor], Tuple[torch.Tensor]]:                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m294 \u001b[2m│   │   \u001b[0mself_outputs = \u001b[96mself\u001b[0m.attention(hidden_states, head_mask, output_attentions)         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m295 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m296 \u001b[0m\u001b[2m│   │   \u001b[0mattention_output = \u001b[96mself\u001b[0m.output(self_outputs[\u001b[94m0\u001b[0m], hidden_states)                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m297 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/lucas/Projects/x-ray/Chest-X-Ray-Pathology-Classifier/env/lib/python3.8/site-packages/torc\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33mh/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/lucas/Projects/x-ray/Chest-X-Ray-Pathology-Classifier/env/lib/python3.8/site-packages/tran\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33msformers/models/vit/\u001b[0m\u001b[1;33mmodeling_vit.py\u001b[0m:\u001b[94m236\u001b[0m in \u001b[92mforward\u001b[0m                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m233 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m234 \u001b[0m\u001b[2m│   │   \u001b[0mcontext_layer = torch.matmul(attention_probs, value_layer)                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m235 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m236 \u001b[2m│   │   \u001b[0mcontext_layer = context_layer.permute(\u001b[94m0\u001b[0m, \u001b[94m2\u001b[0m, \u001b[94m1\u001b[0m, \u001b[94m3\u001b[0m).contiguous()                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m237 \u001b[0m\u001b[2m│   │   \u001b[0mnew_context_layer_shape = context_layer.size()[:-\u001b[94m2\u001b[0m] + (\u001b[96mself\u001b[0m.all_head_size,)        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m238 \u001b[0m\u001b[2m│   │   \u001b[0mcontext_layer = context_layer.view(new_context_layer_shape)                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m239 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mOutOfMemoryError: \u001b[0mCUDA out of memory. Tried to allocate \u001b[1;36m20.00\u001b[0m MiB \u001b[1m(\u001b[0mGPU \u001b[1;36m0\u001b[0m; \u001b[1;36m5.80\u001b[0m GiB total capacity; \u001b[1;36m3.82\u001b[0m GiB already\n",
       "allocated; \u001b[1;36m44.75\u001b[0m MiB free; \u001b[1;36m4.06\u001b[0m GiB reserved in total by PyTorch\u001b[1m)\u001b[0m If reserved memory is >> allocated memory try \n",
       "setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and \n",
       "PYTORCH_CUDA_ALLOC_CONF\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_results = trainer.train()\n",
    "\n",
    "#trainer.save_model()\n",
    "#trainer.log_metrics(\"train\", train_results.metrics)\n",
    "#trainer.save_metrics(\"train\", train_results.metrics)\n",
    "#trainer.save_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = trainer.evaluate()\n",
    "# some nice to haves:\n",
    "trainer.log_metrics(\"eval\", metrics)\n",
    "trainer.save_metrics(\"eval\", metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.], device='cuda:0')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(1).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "from torch import masked_select\n",
    "\n",
    "labels = torch.ones([10, 5], dtype=torch.float32)  # 64 classes, batch size = 10\n",
    "logits = torch.full([10, 5], 0.5)  # A prediction (logit)\n",
    "\n",
    "labels[2,3] = -1.\n",
    "labels[3,3] = -1.\n",
    "labels[6,1] = -1.\n",
    "labels[8,4] = -1.\n",
    "\n",
    "mask = labels > -1.\n",
    "\n",
    "masked_labels = masked_select(labels.view(-1, 5), mask)\n",
    "masked_logits = masked_select(logits.view(-1, 5), mask)\n",
    "\n",
    "loss_fct = nn.BCEWithLogitsLoss()\n",
    "loss = loss_fct(masked_logits, masked_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5541)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.5000, 0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000, 0.5000]]),\n",
       " tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
       "         0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
       "         0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
       "         0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
       "         0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
       "         0.5000]))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits, masked_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
       "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
       "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
       "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
       "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
       "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.view(-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
